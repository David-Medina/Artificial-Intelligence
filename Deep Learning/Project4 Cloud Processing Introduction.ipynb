{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Project4_tdmr.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb5DsTSk8kIS",
        "colab_type": "text"
      },
      "source": [
        "# Point Cloud Processing Introduction\n",
        "A point cloud is a form of non-grid/unstructured data.\n",
        "Unlike pixel arrays in images or voxel arrays in volumetric grids, point clouds represent sets of points without specific order. In other words, a network that\n",
        "consumes a 3D point cloud of N points, needs to be invariant to N! permutations of the point feeding order. \n",
        "\n",
        "In this project, we will introduce you to two methods to process point clouds. Both of them are based on **permutation-invariant operations** that can be used in the unstructured point cloud directly without intermediate representation. \n",
        "\n",
        "The first is **PointNet (pointwise MLP based method)**. [PointNet](https://arxiv.org/abs/1612.00593) is a milestone in point cloud processing. It uses a shared MLP to extract individual point features. An MLP, or Multi-Layer Perceptron, is basically a shared FC layer operating on each point separately.\n",
        "\n",
        "The second is **EdgeConv (graph convolution based method)**. [EdgeConv](https://arxiv.org/abs/1801.07829) uses graph convolutional networks to extract point neighborhood information and set a new state-of-the-art in some point cloud tasks. \n",
        "\n",
        "You will be asked to implement both [PointNet](https://arxiv.org/abs/1612.00593) and [EdgeConv](https://arxiv.org/abs/1801.07829) architectures and train a classification network (left).\n",
        "![](img/cls_sem.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3sZlt5L8kIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for reloading the py file\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNYOe1jz8kIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as data\n",
        "import numpy as np \n",
        "\n",
        "from torchvision.transforms import Compose"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBaFnGdK8kIf",
        "colab_type": "text"
      },
      "source": [
        "# 0. Environment Installnation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi6hhMlX8kIf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "outputId": "c7d3c433-df9e-4942-a7f0-e7ae08bca017"
      },
      "source": [
        "# you can install the required environment by: source env_install.sh \n",
        "!source '/content/env_install.sh'\n",
        "# see the script for details."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/env_install.sh: line 20: conda: command not found\n",
            "/content/env_install.sh: line 21: conda: command not found\n",
            "/content/env_install.sh: line 22: conda: command not found\n",
            "/content/env_install.sh: line 23: conda: command not found\n",
            "/content/env_install.sh: line 24: conda: command not found\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Collecting pyvista\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/b7/332f102a65b07a4eeadd1882e3cdda6b913c0283128d4ebe08adbe9cb75c/pyvista-0.25.3-py3-none-any.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.5)\n",
            "Collecting vtk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/3e/fa760bdbcc20d9f2fedebace22ffc575335bb5f281e98ca9831475ff3f09/vtk-9.0.1-cp36-cp36m-manylinux2010_x86_64.whl (103.4MB)\n",
            "\u001b[K     |████████████████████████████████| 103.4MB 41kB/s \n",
            "\u001b[?25hCollecting appdirs\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/00/2344469e2084fb287c2e0b57b72910309874c3245463acd6cf5e3db69324/appdirs-1.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from pyvista) (2.4.1)\n",
            "Collecting scooby>=0.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/c23497b7312941587c85573572c752127ba68d05f5ba1c0ce66d47f4b9ef/scooby-0.5.5-py3-none-any.whl\n",
            "Collecting meshio<5.0,>=4.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/2d/50709161e1c2b5ca04e910c4d104144bef2776ee41f8c449a0f1ffe5fb33/meshio-4.0.16-py3-none-any.whl (134kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 48.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio->pyvista) (7.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from meshio<5.0,>=4.0.3->pyvista) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.15.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->meshio<5.0,>=4.0.3->pyvista) (3.1.0)\n",
            "Installing collected packages: vtk, appdirs, scooby, meshio, pyvista\n",
            "Successfully installed appdirs-1.4.4 meshio-4.0.16 pyvista-0.25.3 scooby-0.5.5 vtk-9.0.1\n",
            "Installed kernelspec pc in /root/.local/share/jupyter/kernels/pc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASUoONrM8kIp",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data Loading for ModelNet40  (15')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlFgQL-k8kIq",
        "colab_type": "text"
      },
      "source": [
        "Usually, we write the point cloud as $X\\in\\mathbb{R}^{N\\times 3}$. While in pytorch programming, we use `B x 3 x N` layout, where `B` is the batch-size and `N` is the number of points in a single point cloud."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vrPkUhY8kIr",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 augment the point clouds by randomly scaling and shifting  (5')\n",
        "For input $X\\in\\mathbb{R}^{N\\times 3}$, we randomly scale and shift the point clouds. The data is in numpy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8an8tPpR8kIs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def augment_pointcloud(pointcloud):\n",
        "    \"\"\"\n",
        "    for scaling and shifting the point cloud\n",
        "    :param pointcloud:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    ## This function takes as input a point cloud of layout `N x 3`, \n",
        "    ## and outputs the scaled and shifted point cloud of layout `N x 3`.\n",
        "    \n",
        "    ## hint: useful function `np.random.uniform`, `np.multiply` and `np.add`\n",
        "    ## TASK 1.1.1 generate a scale variable of size [3] from a uniform distruction between [2/3, 3/2] of size [3]. scale will be used to multiply with the point cloud\n",
        "    scale = np.random.uniform(2/3, 3/2, 3)\n",
        "    \n",
        "    ## TASK 1.1.2 generate a shift variable of size [3] from a uniform distruction between [-0.2, 0.2] of size [3]. shift will be added to the point cloud\n",
        "    shift = np.random.uniform(-0.2, 0.2, 3)\n",
        "    \n",
        "    ## TASK 1.1.3 scale and then shift the point cloud. \n",
        "    augmented_pointcloud = np.add(np.multiply(pointcloud, scale), shift)\n",
        "    \n",
        "    return augmented_pointcloud.astype('float32')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaiyLT_g8kIv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "outputId": "0b5a7fb7-d2d0-4656-97aa-39bf55e738d2"
      },
      "source": [
        "## debug. random generate data and test your transform here\n",
        "\n",
        "pointcloud = np.random.randn(20, 3)\n",
        "print('before translate:\\n', pointcloud.shape, pointcloud)\n",
        "augmented_pointcloud = augment_pointcloud(pointcloud)\n",
        "print('after translate:\\n', augmented_pointcloud.shape, augmented_pointcloud)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "before translate:\n",
            " (20, 3) [[-0.14891209  0.51869835  0.6840823 ]\n",
            " [ 1.63461503  0.62292578  1.32375758]\n",
            " [ 1.49490639  0.38442752  1.54244531]\n",
            " [-0.25531914 -0.85009941 -1.1503664 ]\n",
            " [ 1.10713402  0.45831698  0.04049189]\n",
            " [ 1.25490414  1.59562664  1.22208296]\n",
            " [-0.44201959  0.0811356  -0.30065056]\n",
            " [-0.65232654  0.16367297  0.95705236]\n",
            " [-0.65779441 -1.00741298 -0.16097829]\n",
            " [ 1.8163905   1.30460426 -0.29973659]\n",
            " [-0.47566862  0.09921598  0.0279773 ]\n",
            " [-0.73966014 -0.27709417 -0.57803497]\n",
            " [ 1.52364229  1.18393305 -1.68493676]\n",
            " [ 0.47015155 -0.50278207 -0.79306278]\n",
            " [ 0.44052075  0.39602798 -1.43700655]\n",
            " [ 0.93706301  2.31450597 -0.23958904]\n",
            " [ 1.29366245 -0.38369794  0.22291237]\n",
            " [ 0.24899391  0.45522179 -0.40668408]\n",
            " [ 0.60268277 -0.17368081 -3.29500493]\n",
            " [ 0.73514484  0.59614337 -1.84076544]]\n",
            "after translate:\n",
            " (20, 3) [[-0.35498613  0.55981797  0.6179654 ]\n",
            " [ 1.922421    0.6793441   1.1897595 ]\n",
            " [ 1.7440253   0.4058386   1.3852406 ]\n",
            " [-0.49085858 -1.0098947  -1.0218151 ]\n",
            " [ 1.2488742   0.49057373  0.04267158]\n",
            " [ 1.4375637   1.7948201   1.0988744 ]\n",
            " [-0.7292586   0.05802887 -0.26226947]\n",
            " [-0.9978021   0.15268125  0.8619684 ]\n",
            " [-1.0047841  -1.1902992  -0.13741897]\n",
            " [ 2.1545322   1.4610808  -0.2614525 ]\n",
            " [-0.77222544  0.07876312  0.03148501]\n",
            " [-1.1093194  -0.35278264 -0.5102184 ]\n",
            " [ 1.7807186   1.3226973  -1.4996579 ]\n",
            " [ 0.43550363 -0.6115975  -0.70242786]\n",
            " [ 0.3976677   0.4191418  -1.2780375 ]\n",
            " [ 1.0317085   2.619218   -0.20768769]\n",
            " [ 1.4870546  -0.4750339   0.20573394]\n",
            " [ 0.15310478  0.48702422 -0.35705093]\n",
            " [ 0.60473436 -0.23419003 -2.9388685 ]\n",
            " [ 0.7738767   0.64863056 -1.6389502 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SPV6y_l8kIz",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Load dataset ModelNet40 for Point Cloud Classification (10')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzcaNf3A8kI0",
        "colab_type": "text"
      },
      "source": [
        "### ModelNet40\n",
        "ModelNet40 contains 12,311 meshed CAD models from 40 categories.  \n",
        "Given a point cloud $X\\in\\mathbb{R}^{N\\times 3}$, the goal is to predict which category this point cloud belongs to. \n",
        "\n",
        "By loading this dataset, we have data of shape `B x 3 x N` and label of shape `B`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3ZlHFLF8kI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Here we provide the basic function to load and download the ModelNet40 dataset. Your job is to write a data loader for ModelNet40. \n",
        "import os\n",
        "import glob\n",
        "import h5py\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "def download(datadir):\n",
        "    if not os.path.exists(datadir):\n",
        "        os.makedirs(datadir)\n",
        "    if not os.path.exists(os.path.join(datadir, 'modelnet40_ply_hdf5_2048')):\n",
        "        www = 'https://shapenet.cs.stanford.edu/media/modelnet40_ply_hdf5_2048.zip'\n",
        "        print('downloading the dataset now. This may take a while. ')\n",
        "        zipfile = os.path.basename(www)\n",
        "        os.system('wget %s; unzip %s' % (www, zipfile))\n",
        "        os.system('mv %s %s' % (zipfile[:-4], datadir))\n",
        "        os.system('rm %s' % (zipfile))\n",
        "\n",
        "def load_data(datadir, partition):\n",
        "    download(datadir)\n",
        "    all_data = []\n",
        "    all_label = []\n",
        "    for h5_name in glob.glob(os.path.join(datadir, 'modelnet40_ply_hdf5_2048', 'ply_data_%s*.h5'%partition)):\n",
        "        with h5py.File(h5_name, 'r') as f:\n",
        "            data = f['data'][:].astype('float32')\n",
        "            label = f['label'][:].astype('int64')\n",
        "        all_data.append(data)\n",
        "        all_label.append(label)\n",
        "    all_data = np.concatenate(all_data, axis=0)\n",
        "    all_label = np.concatenate(all_label, axis=0)\n",
        "    return all_data, all_label\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZmk2A4x8kI6",
        "colab_type": "text"
      },
      "source": [
        "### Task 1.2.1 Finish the data loader for ModelNet40.  (5')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnvYxR208kI6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelNet40(data.Dataset):\n",
        "    \"\"\"\n",
        "    This is the data loader for ModelNet40\n",
        "    ModelNet40 contains 12,311 meshed CAD models from 40 categories.\n",
        "    \n",
        "    num_points: 1024 by default \n",
        "    datadir: we will put data in \"./data/modelnet40\". new one /content/drive/My Drive/Deep Learning/project4/data\n",
        "    paritition: train or test\n",
        "    \"\"\"\n",
        "        \n",
        "    def __init__(self, num_points=1024, datadir=\"/data/modelnet40\", partition='train'):\n",
        "        self.data, self.label = load_data(datadir, partition)\n",
        "        self.num_points = num_points\n",
        "        self.partition = partition\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        pointcloud = self.data[item][:self.num_points]\n",
        "        label = self.label[item]\n",
        "\n",
        "        # Task 1.2.1 augment the pointcloud when partition == 'train', and then shuffle points in the point cloud (randomly reorder). \n",
        "        if self.partition == 'train':\n",
        "          pointcloud = augment_pointcloud(pointcloud)\n",
        "          np.random.shuffle(pointcloud)\n",
        "        \n",
        "        return pointcloud, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def num_classes(self):\n",
        "        return np.max(self.label) + 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rql1_W65mG86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# please install pyvista.\n",
        "!pip install pyvista"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVKZ9V_Q8kI-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "fca91d17-3b0f-4388-8461-950e78dea5fd"
      },
      "source": [
        "\n",
        "def vis_pc(pointcloud):\n",
        "    import pyvista as pv\n",
        "    plotter = pv.Plotter()\n",
        "    points_voxelized = pointcloud\n",
        "    point_cloud = pv.PolyData(points_voxelized)\n",
        "    plotter.show_grid()\n",
        "    plotter.add_mesh(point_cloud, point_size=10., render_points_as_spheres=True)\n",
        "    plotter.show()\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyvista in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
            "Requirement already satisfied: vtk in /usr/local/lib/python3.6/dist-packages (from pyvista) (9.0.1)\n",
            "Requirement already satisfied: scooby>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from pyvista) (0.5.5)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.6/dist-packages (from pyvista) (1.4.4)\n",
            "Requirement already satisfied: meshio<5.0,>=4.0.3 in /usr/local/lib/python3.6/dist-packages (from pyvista) (4.0.16)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from pyvista) (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyvista) (1.18.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from meshio<5.0,>=4.0.3->pyvista) (1.6.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from imageio->pyvista) (7.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->meshio<5.0,>=4.0.3->pyvista) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkHY20jR8kJN",
        "colab_type": "text"
      },
      "source": [
        "### Task 1.2.2 debug the data loader. (5')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZnrTY3M8kJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "94f04d2c-a6b5-45b0-f98e-5367eccd470e"
      },
      "source": [
        "# todo: \n",
        "# The dataset downloading takes maybe 15 mins. Please be patient. It will be appear in the root folder at first then be moved to ./data/ automatically. \n",
        "trainset = torch.utils.data.DataLoader(ModelNet40())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading the dataset now. This may take a while. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-3acd5f1326e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# todo:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# The dataset downloading takes maybe 15 mins. Please be patient. It will be appear in the root folder at first then be moved to ./data/ automatically.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelNet40\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-cde9dea6c4c4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_points, datadir, partition)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_points\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatadir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/data/modelnet40\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_points\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-5e7234f5cfc4>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(datadir, partition)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mall_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mall_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mall_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mall_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: need at least one array to concatenate"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDRWCBCz8kJQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Task 1.2.2 show the third point cloud in trainset.data (index is 2 since the index begins from 0 in python)\n",
        "pointcloud = trainset.dataset[2][0]\n",
        "#vis_pc(pointcloud)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vE755MC8kJY",
        "colab_type": "text"
      },
      "source": [
        "# 2 PointNet (Pointwise MLP) (45')\n",
        "\n",
        "[PointNet](https://arxiv.org/abs/1612.00593) is a milestone in point cluod processing. It use a shared MLP to extract individual point features.   \n",
        "In this section, you will be asked to implement classification step by step.   \n",
        "**Please Read Section 4.2 and Appendix C of the paper.**\n",
        "\n",
        "\n",
        "![pointnet](img/pointnet.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4FvcRuV8kJZ",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 Basic Modules (5')\n",
        "We will guide you to build the basic modules for pointwise MLP based network at first. Then you can build any network easily using these basic modules.   \n",
        "We will implement the **shared MLP layer** using $1\\times1$ Conv1d and implement **MLP** layer using nn.Linear. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQGjebOF8kJb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import Sequential as Seq, Linear as Lin, Conv1d\n",
        "\n",
        "def act_layer(act, inplace=False, neg_slope=0.2, n_prelu=1):\n",
        "    \"\"\"\n",
        "    activation layer\n",
        "    :param act:\n",
        "    :param inplace:\n",
        "    :param neg_slope:\n",
        "    :param n_prelu:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    act = act.lower()\n",
        "    if act == 'relu':\n",
        "        layer = nn.ReLU(inplace)\n",
        "    elif act == 'leakyrelu':\n",
        "        layer = nn.LeakyReLU(neg_slope, inplace)\n",
        "    elif act == 'prelu':\n",
        "        layer = nn.PReLU(num_parameters=n_prelu, init=neg_slope)\n",
        "    else:\n",
        "        raise NotImplementedError('activation layer [%s] is not found' % act)\n",
        "    return layer\n",
        "\n",
        "        \n",
        "# Now, let's implement a sharedMLP layer. It is implmented by using Conv1d with kernel size equals to 1. \n",
        "class Conv1dLayer(Seq):\n",
        "    def __init__(self, channels, act='relu', norm=True, bias=True):\n",
        "        m = []\n",
        "        for i in range(1, len(channels)):\n",
        "            m.append(Conv1d(channels[i - 1], channels[i], 1, bias=bias))\n",
        "            if norm:\n",
        "                m.append(nn.BatchNorm1d(channels[i]))\n",
        "            if act:\n",
        "                m.append(act_layer(act))\n",
        "        super(Conv1dLayer, self).__init__(*m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGt82YEC8kJd",
        "colab_type": "text"
      },
      "source": [
        "### Task 2.1 Implement MLP layer according to the Conv1dLayer above. (5')\n",
        "the same as Conv1dLayer class, we will implement MLP layer with normalization layer, activation layer and a **dropout** layer after the activation.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvAOzYt58kJd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MLP(Seq):\n",
        "    \"\"\"\n",
        "    Given input with shape [B, C_in]\n",
        "    return output with shape [B, C_out] \n",
        "    \"\"\"\n",
        "    def __init__(self, channels, act='relu', norm=True, bias=True, dropout=0.5):\n",
        "        # todo:\n",
        "        m = []\n",
        "        for i in range(1, len(channels)):\n",
        "            # todo \n",
        "            m.append(Conv1d(channels[i - 1], channels[i], 1, bias=bias))\n",
        "            if norm:\n",
        "                m.append(nn.BatchNorm1d(channels[i]))\n",
        "            if act:\n",
        "                m.append(act_layer(act))\n",
        "            if dropout > 0:\n",
        "                # todo: \n",
        "                m.append(nn.Dropout(p=dropout))\n",
        "\n",
        "        # todo\n",
        "        super(MLP, self).__init__(*m)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qM5Trzw8kJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# debug code for act_layer, MLP, and Conv1dLayer\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "x = torch.randn(8, 3, 100).to(DEVICE)\n",
        "conv = Conv1dLayer().to(DEVICE)\n",
        "out = conv(x)\n",
        "print(out.shape, transform.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLR3C2z58kJj",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 T-Net and Joint Alignment Network (15')\n",
        "\n",
        "Joint Alignment Network predicts an affine transformation matrix by a mini-network (T-net in paper Fig 2) and directly apply this transformation to the coordinates of input points. \n",
        "\n",
        "T-Net takes as input matrix of size $N \\times K$, and outputs a transformation matrix of size $K \\times K$. \n",
        "In programming, the input size of this module is `B x K x N` and output size is `B x K x K`.\n",
        "\n",
        "The T-Net resembles the big network and is composed by basic modules of point independent feature extraction, max pooling and fully connected layers. \n",
        "For the shared MLP, use a structure like this `(Conv1d(64), BN, ReLU, Conv1d(128), BN, ReLU, Conv1d(1024), BN, ReLU)`.\n",
        "For the MLP after global max pooling, use a structure like this `(Conv1d(512), BN, ReLU, Conv1d(256), BN, ReLU, Conv1d(K*K)`.\n",
        "\n",
        "Remember our basic modules? MLP and Conv1dLayer. You can use them to build the T-Net simply. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRilGH6s8kJj",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.1 T-Net architecture (10')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlxRnZv_8kJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Transformation(nn.Module):\n",
        "    def __init__(self, k=3):\n",
        "        super(Transformation, self).__init__()\n",
        "        self.k = k\n",
        "        # Task 2.2.1 T-Net architecture\n",
        "        \n",
        "        # self.convs consists of 3 convolution layer. \n",
        "        # please look at the description above. \n",
        "\n",
        "        self.conv1 = Conv1dLayer([self.k,64,128,1024])\n",
        "        self.conv2 = Conv1dLayer([1024,512,256])\n",
        "\n",
        "        self.fcs = Conv1dLayer([256, self.k*self.k], norm=False, act=None) # no relu or BN at the last layer. \n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Forward of T-Net architecture\n",
        "        \n",
        "        B, K, N = x.shape # batch-size, dim, number of points\n",
        "        ## forward of shared mlp\n",
        "        # input - B x K x N\n",
        "        # output - B x 1024 x N\n",
        "        x = x.transpose(1,2)\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        maxpool = nn.MaxPool1d(x.shape[2])\n",
        "        x = maxpool(x)\n",
        "        ## global max pooling\n",
        "        # input - B x 1024 x N\n",
        "        # output - B x 1024\n",
        "        x = self.conv2(x)\n",
        "        ## mlp\n",
        "        # input - B x 1024\n",
        "        # output - B x (K*K)\n",
        "        x = self.fcs(x)\n",
        "        ## reshape the transformation matrix to B x K x K\n",
        "        identity = torch.eye(self.k, device=x.device)\n",
        "        x = x.view(B, self.k, self.k) + identity[None]\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWf0QY5j8kJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## random generate data and test this network\n",
        "x = torch.randn(10, 100, 3).to(DEVICE)\n",
        "mytnet = Transformation(k=3).to(DEVICE)\n",
        "print('input of the Transformation:\\n', x.shape)\n",
        "trans = mytnet(x) \n",
        "print('Transformation matrix:\\n', trans.shape)\n",
        "\n",
        "# the out.shape should be torch.Size([10, 3, 3]), given input x = torch.randn(10, 3, 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beqaB-lv8kJo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stn(x, transform_matrix=None):\n",
        "    # spatial transformantion network. this is the matrix multiplication part inside the joint alignment network.\n",
        "    x = x.transpose(2, 1)\n",
        "    x = torch.bmm(x, transform_matrix)\n",
        "    x = x.transpose(2, 1)\n",
        "    return x   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bokABHth8kJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_out = stn(x.transpose(1,2), trans)\n",
        "print('after Transformation:\\n', x_out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATtMLrmU8kJs",
        "colab_type": "text"
      },
      "source": [
        "### 2.2.2 Regularization Loss for T-Net (5')\n",
        "$$L_{reg}=\\|I-TT^\\intercal\\|^2_F$$\n",
        "\n",
        "The output of `Transformation` network is of size `B x K x K`. The module `OrthoLoss` computes this norm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kApnyPSb8kJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OrthoLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OrthoLoss, self).__init__()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        ## hint: useful function `torch.bmm` or `torch.matmul`\n",
        "        ## TASK 2.2.2\n",
        "        ## compute the matrix product\n",
        "        x = x.view(x.shape[0], -1)\n",
        "        prod = torch.matmul(x, torch.transpose(x, 0, 1))  # TT^T\n",
        "        prod = torch.eye(prod.shape[0]).to(DEVICE) - prod # minus\n",
        "        norm = torch.norm(prod)\n",
        "        return norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWYjJjjO8kJv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## random generate data and test this network\n",
        "print(OrthoLoss()(trans))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSBHmc-_8kJw",
        "colab_type": "text"
      },
      "source": [
        "## 2.3 PointNet Classification Network (15')\n",
        "In this subsection, you will be asked to implement the feature network (the top branch).\n",
        "\n",
        "Local features are a matrix of size `B x 64 x N`, which will be used in the segmentation task. (We only return the local feature but never uses it for the reason that we focus on claissfication)\n",
        "\n",
        "Global features are a matrix of size `B x 1024`, which will be used in the classification task."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzONwuVM8kJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PointNet(nn.Module):\n",
        "    def __init__(self, num_classes=40, alignment=False):\n",
        "        super(PointNet, self).__init__()\n",
        "        # look at the description under 2.2 or refer to the paper if you need more details\n",
        "        \n",
        "        self.alignment = alignment\n",
        "        \n",
        "        ## `input_transform` calculates the input transform matrix of size `3 x 3`\n",
        "        if self.alignment:\n",
        "            self.input_transform = Transformation(k=3)\n",
        "        \n",
        "        ## TASK 2.3.1 \n",
        "        ## define your network layers here\n",
        "        ## local feature\n",
        "        ## one shared mlp layer (shared MLP is actually 1x1 convolution. You can use our conv1dLayer)\n",
        "        ## input size: B x 3 x N\n",
        "        ## output size: B x 64 x N\n",
        "\n",
        "        self.conv1 = Conv1dLayer([3, 64])\n",
        "    \n",
        "        ## `feature_transform` calculates the feature transform matrix of size `64 x 64`\n",
        "        if self.alignment:\n",
        "            ## TASK 2.3.2 transormation layer\n",
        "            self.feature_transform = Transformation(k=64)\n",
        "        \n",
        "        ## TASK 2.3.3\n",
        "        ## define your network layers here\n",
        "        ## global feature\n",
        "        ## 2 layers of shared mlp.  64 -> 128 -> 1024\n",
        "        ## input size: B x 64 x N\n",
        "        ## output size: B x 1024 x N\n",
        "        \n",
        "        self.conv2s = Conv1dLayer([64, 128, 1024])\n",
        "        \n",
        "        # Task 2.3.4 classification layer\n",
        "        # 3 MLP layers. 1024 -> 512 -> 256 -> num_classes. \n",
        "        # there is a dropout in the second layer. dropout ratio = 05\n",
        "        # no relu or BN at the last layer.\n",
        "        self.classifier = Seq(\n",
        "            Conv1dLayer([1024, 512]),\n",
        "            MLP([512, 256], dropout=0.5),\n",
        "            Conv1dLayer([256, num_classes], norm=False, act=None)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        ## task 2.3.5 apply the input transform in the coordinate domain\n",
        "        if self.alignment:\n",
        "            # get transformation matrix then apply to x\n",
        "            transform = self.input_transform(x)\n",
        "            # apply transorm into the input feature x\n",
        "            x = stn(x.transpose(2,1), transform_matrix=transform)\n",
        "\n",
        "        ## forward of shared mlp\n",
        "        # input - B x K x N\n",
        "        # output - B x 64 x N\n",
        "        x = self.conv1(x)\n",
        "        \n",
        "        ## task 2.3.7 another transform in the feauture domain\n",
        "        if self.alignment:\n",
        "            transform = self.feature_transform(x.transpose(1,2))\n",
        "            x = stn(x, transform_matrix=transform)\n",
        "        else:\n",
        "            transform = None\n",
        "        #local_feature = x  # this can be used in segmentation task. we comment it out here. \n",
        "        \n",
        "        ## TASK 2.3.8\n",
        "        ## forward of shared mlp\n",
        "        # input - B x 64 x N\n",
        "        # output - B x 1024 x N\n",
        "        x = self.conv2s(x)\n",
        "        \n",
        "        ## global max pooling\n",
        "        # input - B x 1024 x N\n",
        "        # output - B x 1024\n",
        "        x = torch.max(x, dim=2, keepdim=True)[0]\n",
        "        global_feature = x.view(-1, 1024)\n",
        "        \n",
        "        ## summary:\n",
        "        ## global_feature: B x 1024\n",
        "        ## local_feature: B x 64 x N\n",
        "        ## transform: B x K x K\n",
        "        \n",
        "        # 2.3.10 classification\n",
        "        out = self.classifier(x)\n",
        "        return out, transform"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6B3SAxMN8kJz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## random generate data and test this network\n",
        "x = torch.randn(10, 100, 3).to(DEVICE)\n",
        "net = PointNet(alignment=True)\n",
        "out, transform = net(x)\n",
        "print(out.shape, transform.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E--2Yu7r8kJ1",
        "colab_type": "text"
      },
      "source": [
        "## 2.4 Train PointNet on ModelNet40"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bLtqCZD8kJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.metrics as metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32f2C-AZ8kJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0.\n",
        "        self.avg = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0.\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RA7XjgfO8kJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_ckpt(model, optimizer, scheduler, jobname, name_post, ckpt_dir='/content/drive/My Drive/Deep Learning/project4/ckpt'):\n",
        "    # ------------------ save ckpt\n",
        "    if not os.path.exists(ckpt_dir):\n",
        "        os.makedirs(ckpt_dir)\n",
        "    filename = '{}/{}_{}_model.pth'.format(ckpt_dir, jobname, name_post)\n",
        "    model_cpu = {k: v.cpu() for k, v in model.state_dict().items()}\n",
        "    state = {\n",
        "        'state_dict': model_cpu,\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'scheduler_state_dict': scheduler.state_dict(),\n",
        "    }\n",
        "    torch.save(state, filename)\n",
        "    print('save a new best model into {}'.format(filename))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpWdJHRj8kJ6",
        "colab_type": "text"
      },
      "source": [
        "### TASK 2.4 train_step function (5')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_vyuOKL8kJ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(model, train_loader, optimizer, criterion, train_losses, reg):\n",
        "    model.train()\n",
        "\n",
        "    train_pred = []\n",
        "    train_true = []\n",
        "    for i, (data, label) in enumerate(train_loader):\n",
        "        if i%100 == 0: print('train_step ', i)\n",
        "        # todo: data preprocess (to GPU, and permute)\n",
        "        data, label = data.to(DEVICE), label.to(DEVICE)\n",
        "\n",
        "        # TASK 2.4 todo: optimizer zero grad, forward pass, criterion\n",
        "        # optimizer zero grad\n",
        "            # TASK 2.4 todo: \n",
        "        optimizer.zero_grad()\n",
        "            \n",
        "        # forward pass\n",
        "            # TASK 2.4 todo:\n",
        "        logits, trans = model(data)\n",
        "        # criterion\n",
        "            # TASK 2.4 todo: \n",
        "        loss = criterion(logits, label)\n",
        "\n",
        "        # regulartization loss for T-Net\n",
        "        if trans is not None:\n",
        "                loss += reg(trans) * 0.001\n",
        "        \n",
        "        # backward part and optimize\n",
        "        # TASK 2.4 todo:\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.update(loss.item())\n",
        "\n",
        "        preds = logits.max(dim=1)[1]\n",
        "        train_true.append(label.cpu().numpy())\n",
        "        train_pred.append(preds.detach().cpu().numpy())\n",
        "\n",
        "    train_true = np.concatenate(train_true)\n",
        "    train_pred = np.concatenate(train_pred)\n",
        "    overall_acc = metrics.accuracy_score(train_true, train_pred)\n",
        "    class_avg_acc = metrics.balanced_accuracy_score(train_true, train_pred)\n",
        "    \n",
        "    print('\\rTrain Iter: [{:03d}/{:03d}] Loss: {:.4f} OA:{:.4f} AvgAcc:{:.4f}'.format(i+1, len(train_loader), loss.item(), overall_acc, class_avg_acc, end='', flush=True))\n",
        "    return overall_acc, class_avg_acc, train_losses\n",
        "\n",
        "\n",
        "def test(model, test_loader, criterion, test_losses, reg):\n",
        "    model.eval()\n",
        "    test_true = []\n",
        "    test_pred = []\n",
        "    with torch.no_grad():\n",
        "        for i, (data, label) in enumerate(test_loader):\n",
        "            if i%10 == 0: print('test ', i)\n",
        "            data, label = data.to(DEVICE), label.to(DEVICE)\n",
        "            # test forward and loss\n",
        "            # TASK 2.4 todo: \n",
        "            logits, trans = model(data)\n",
        "            loss = criterion(logits, label)  \n",
        "\n",
        "            pred = logits.max(dim=1)[1]\n",
        "            test_true.append(label.cpu().numpy())\n",
        "            test_pred.append(pred.detach().cpu().numpy())\n",
        "\n",
        "            test_losses.update(loss.item())\n",
        "\n",
        "        test_true = np.concatenate(test_true)\n",
        "        test_pred = np.concatenate(test_pred)\n",
        "        overall_acc = metrics.accuracy_score(test_true, test_pred)\n",
        "        class_avg_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
        "        print('\\rTest Iter: [{:03d}/{:03d}] Loss: {:.4f} OA:{:.4f} AvgAcc:{:.4f}'.format(i+1, len(train_loader), loss.item(), overall_acc, class_avg_acc, end='', flush=True))\n",
        "    return overall_acc, class_avg_acc, test_losses\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLT-H-vD8kJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# main train function for classification\n",
        "def train_cls(train_loader, test_loader, network, optimizer, scheduler, criterion, epochs):\n",
        "    reg = OrthoLoss()\n",
        "    train_losses, test_losses = AverageMeter(), AverageMeter()\n",
        "    best_test_overall_acc = 0. \n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch:[{:02d}/{:02d}]'.format(epoch+1, epochs))\n",
        "        train_overall_acc, train_class_avg_acc, train_losses = train_step(network, train_loader, optimizer, criterion, train_losses, reg)\n",
        "        test_overall_acc, test_class_avg_acc, test_losses = test(network, test_loader, criterion, test_losses, reg)\n",
        "        \n",
        "        if test_overall_acc > best_test_overall_acc:\n",
        "            best_test_overall_acc = test_overall_acc\n",
        "            class_avg_acc_when_best = test_class_avg_acc\n",
        "            print(\"Got a new best model on Test with Overall ACC {:.4f}. \"\n",
        "                         \"Its avg acc is {:.4f}\".format(best_test_overall_acc, class_avg_acc_when_best))\n",
        "            save_ckpt(network, optimizer, scheduler, 'PointNet', 'best')\n",
        "            \n",
        "        scheduler.step()\n",
        "        print('Average Train Loss: {:.4f}; Train Overall Acc: {:.4f}; Test Overall ACC: {:.4f}; Best Test Overall Acc {:.4f}'.format(train_losses.avg, train_overall_acc, test_overall_acc, best_test_overall_acc))\n",
        "        \n",
        "        print(\"------------------------------------------------------------\\n\")\n",
        "    print('Finish Training PointNet. The best Test overall acc {:.4f}'.format(best_test_overall_acc))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfbpBqgj8kJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "epochs = 250 # you can change the value to a small number for debugging\n",
        "batch_size = 32\n",
        "test_batch_size = 50\n",
        "lr = 0.001\n",
        "\n",
        "network = PointNet(40, alignment=True).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_loader = DataLoader(ModelNet40(partition='train', num_points=1024),\n",
        "                          num_workers=4, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(ModelNet40(partition='test', num_points=1024),\n",
        "                         num_workers=4, batch_size=test_batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "# start training\n",
        "train_cls(train_loader, test_loader, network, optimizer, scheduler, criterion, epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCYdhWMJ8kJ_",
        "colab_type": "text"
      },
      "source": [
        "## TASK 2.5 Train PointNet and fill your best overall accuracy on testing dataset here. (should be higher than 86%)  (10')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2_0uchjHHP7",
        "colab_type": "text"
      },
      "source": [
        "After several trials, the maximum epochs that the session supported was 28 (after running for almost 8 hours), reaching a BEST TEST OVERAL ACCURACY of **83.27%**. By the look of the training (how it was improving with each epoch), I am sure that it would have reached the required 86% accuracy if the session would have gone for longer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHLMZUkZNx_b",
        "colab_type": "text"
      },
      "source": [
        "**Link to .txt with the 28 epochs' results**: https://drive.google.com/file/d/13iky0thbg1Y2BLhwyghYA1QwcPbVpccv/view?usp=sharing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7GBY2kk8kKB",
        "colab_type": "text"
      },
      "source": [
        "# 3. DGCNN with EdgeConv (GCN based Method) \n",
        "DGCNN Architecture (Read Section 3. of [EdgeConv Paper](https://arxiv.org/abs/1801.07829))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngOQtD8A8kKB",
        "colab_type": "text"
      },
      "source": [
        "[EdgeConv](https://arxiv.org/abs/1801.07829) uses graph convolutional networks to extract point neighborhood information and set a new state-of-the-art in some point cloud tasks. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAr0G_C58kKC",
        "colab_type": "text"
      },
      "source": [
        "![title](img/dgcnn.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44BKQFgl8kKC",
        "colab_type": "text"
      },
      "source": [
        "## brief introduction to Graph Convolution.\n",
        "A graph convolution can be created using the message passing framework:\n",
        "$$ \\mathbf{x}_{i}^{\\prime}=\\gamma_{\\mathbf{\\Theta}}\\left(\\mathbf{x}_{i}, \\square_{j \\in \\mathcal{N}(i)} \\phi_{\\Theta}\\left(\\mathbf{x}_{i}, \\mathbf{x}_{j}, \\mathbf{e}_{j, i}\\right)\\right)$$\n",
        "\n",
        "where $square$ denotes a differentiable, permutation invariant aggregation function, e.g., sum, mean or max.   \n",
        "$\\gamma_{\\mathbf{\\Theta}}$ and $\\phi_{\\Theta}$ denote differentiable functions such as MLPs, $1\\times1$ convolutions.   \n",
        "$x_i, x_j, e_{ij}$ is the center feature, the neighbor feature, and the edge feature between node $i$ and $j$.   \n",
        "$\\mathcal{N}(i)$ is the neighborhood of node $i$.  \n",
        "$ \\mathbf{x}_{i}^{\\prime}$ is the output feature of center node $i$.  \n",
        "\n",
        "[Further reading](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40aywCjA8kKC",
        "colab_type": "text"
      },
      "source": [
        "EdgeConv:\n",
        "$$\\mathbf{h}^{v_{l+1}} =\\textit{max}\\left(\\{\\textit{mlp}(\\textit{concat}(\\mathbf{h}_{v_{l}}, \\mathbf{h}_{u_{l}}-\\mathbf{h}_{v_{l}}))|u_{l}\\in \\mathcal{N}^{(d)}(v_{l})\\}\\right)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmAdHMcd8kKE",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Basic KNN Modules (5')\n",
        "To build a graph convolutional network, we have to build three kinds of basic modules at first. \n",
        "1. the neighborhood querying modules (KNN)\n",
        "2. the permutation invariant convolution/mlp modules with BN, activation layer inside. \n",
        "3. the graph convolution modules using 1. and 2. \n",
        "\n",
        "We will guide you to build these basic modules at first. Then you can build any graph convolutional network easily using these basic modules. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2aNXfmt8kKF",
        "colab_type": "text"
      },
      "source": [
        "First is the basic modules for neighborhood querying. We use KNN here to find k nearest neighbors (include the center node). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CBmXL558kKF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def knn(x, k):\n",
        "    \"\"\"\n",
        "    Given point features x [B, C, N, 1], and number of neighbors k (int)\n",
        "    Return the idx for the k neighbors of each point. \n",
        "    So, the shape of idx: [B, N, k]\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        x = x.squeeze(-1)\n",
        "        inner = -2 * torch.matmul(x.transpose(2, 1), x)\n",
        "        xx = torch.sum(x ** 2, dim=1, keepdim=True)\n",
        "        pairwise_distance = -xx - inner - xx.transpose(2, 1)\n",
        "\n",
        "        idx = pairwise_distance.topk(k=k, dim=-1)[1]  # (batch_size, num_points, k)\n",
        "    return idx\n",
        "\n",
        "def batched_index_select(x, idx):\n",
        "    \"\"\"\n",
        "    This can be used for neighbors features fetching\n",
        "    Given a pointcloud x, return its k neighbors features indicated by a tensor idx.\n",
        "    :param x: torch.Size([batch_size, num_dims, num_vertices, 1])\n",
        "    :param index: torch.Size([batch_size, num_vertices, k])\n",
        "    :return: torch.Size([batch_size, num_dims, num_vertices, k])\n",
        "    \"\"\"\n",
        "\n",
        "    batch_size, num_dims, num_vertices = x.shape[:3]\n",
        "    k = idx.shape[-1]\n",
        "    idx_base = torch.arange(0, batch_size, device=idx.device).view(-1, 1, 1) * num_vertices\n",
        "    idx = idx + idx_base\n",
        "    idx = idx.view(-1)\n",
        "\n",
        "    x = x.transpose(2, 1).contiguous()\n",
        "    feature = x.view(batch_size * num_vertices, -1)[idx, :]\n",
        "    feature = feature.view(batch_size, num_vertices, k, num_dims).permute(0, 3, 1, 2)\n",
        "    return feature\n",
        "\n",
        "def get_center_feature(x, k):\n",
        "    \"\"\"\n",
        "    Given you a point cloud, and neighbors k, return the center features.\n",
        "    :param x: torch.Size([batch_size, num_dims, num_vertices, 1])\n",
        "    :param k: int\n",
        "    :return: torch.Size([batch_size, num_dims, num_vertices, k])\n",
        "    \"\"\"\n",
        "    x = x.repeat(1, 1, 1, k)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVNajJqA8kKH",
        "colab_type": "text"
      },
      "source": [
        "### TASK3.1.1 try the KNN modules (5')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKl7bWDh8kKI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# please use an example to get familar with knn and the neighborhood features. \n",
        "k = 9\n",
        "trainset = ModelNet40(partition='train')\n",
        "pointcloud = trainset.data[2]\n",
        "print(pointcloud.shape)\n",
        "\n",
        "# TASK 3.2 write a simple example to try our knn, batched_index_select, get_center_feature functions. \n",
        "# variable pointcloud is a numpy narray, transform to the standard format of a pytorch tensor \n",
        "x = torch.from_numpy(pointcloud)\n",
        "x = x.view(32,3,-1,1)\n",
        "idx = knn(x, k)\n",
        "x_j = batched_index_select(x, idx)  # use x_j to indicate neighbor features.\n",
        "x_i = get_center_feature(x, k)      # use x_i to indicate center features. \n",
        "\n",
        "print(x.shape, x_j.shape, x_i.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdysNQTX8kKK",
        "colab_type": "text"
      },
      "source": [
        "## 3.2 Basic Convolution Modules (2')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR5QiIkr8kKL",
        "colab_type": "text"
      },
      "source": [
        "### TASK3.2 build the basic Conv2dLayer\n",
        "In seciton 2.1, we build a Conv1dLayer there for the pointcloud [B, C, N]. \n",
        "Here we want to build a similar convolution layer for the point cloud [B, C, N, k]. We still use $1x1$ convolution for the permuation invariant operation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLqs2Ypf8kKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv2dLayer(Seq):\n",
        "    def __init__(self, channels, act='relu', norm=True, bias=False, kernel_size=1, stride=1, dilation=1, drop=0.5):\n",
        "      m = []\n",
        "      for i in range(1, len(channels)):\n",
        "        m.append(nn.Conv2d(channels[i - 1], channels[i], kernel_size=kernel_size, bias=bias, stride=stride, dilation=dilation))\n",
        "        if norm:\n",
        "            m.append(nn.BatchNorm2d(channels[i]))\n",
        "        if act:\n",
        "            m.append(act_layer(act))\n",
        "        if drop > 0:\n",
        "            m.append(nn.Dropout2d(p=drop))\n",
        "      super(Conv2dLayer, self).__init__(*m)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vqukX7P8kKN",
        "colab_type": "text"
      },
      "source": [
        "## 3.3 Basic Graph Convolution Modules (8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADYNMEil8kKO",
        "colab_type": "text"
      },
      "source": [
        "### TASK3.3: Write the forwad pass of EdgeConv.  (4')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPIDKwHx8kKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EdgeConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    Static EdgeConv graph convolution layer (with activation, batch normalization) for point cloud [B, C, N, 1]. \n",
        "    This operation perform the EdgeConv given the knn idx. \n",
        "    input: B, C, N, 1\n",
        "    return: B, C, N, 1\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, act='leakyrelu', norm=True, bias=False, aggr='max'):\n",
        "        super(EdgeConv2d, self).__init__()\n",
        "        self.nn = Conv2dLayer([in_channels * 2, out_channels], act, norm, bias)\n",
        "        if aggr == 'mean':\n",
        "            self.aggr = torch.mean\n",
        "        else:\n",
        "            self.aggr = torch.max\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        # TASK3.3: Write the forwad pass of EdgeConv. \n",
        "        x_i = get_center_feature(x, edge_index.shape[2])\n",
        "        x_j = batched_index_select(x, edge_index)\n",
        "        x = self.aggr(self.nn(torch.cat((x_i, x_j - x_i), dim=1)), dim=3)[0]\n",
        "        x = x.view(x.shape[0], x.shape[1], x.shape[2], 1)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHk1_6tI8kKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the x, idx here are from the 3.2\n",
        "print(x.shape)\n",
        "out = EdgeConv2d(3, 64)(x, idx)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-Ogs08U8kKT",
        "colab_type": "text"
      },
      "source": [
        "### TASK3.3.1: Write the dynamic version EdgeConv. (4')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWg_kYoi8kKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DynEdgeConv2d(EdgeConv2d):\n",
        "    \"\"\"\n",
        "        Dynamic EdgeConv graph convolution layer (with activation, batch normalization) for point cloud [B, C, N, 1]\n",
        "        This operaiton will build the knn graph at first, then perform the static EdgeConv\n",
        "        input: B, C, N, 1\n",
        "        return: B, C, N, 1\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, k=9, act='relu',\n",
        "                 norm=True, bias=False, aggr='max'):\n",
        "        # inherit function\n",
        "        super(DynEdgeConv2d, self).__init__(in_channels, out_channels)\n",
        "        self.k = k\n",
        "\n",
        "    def forward(self, x):\n",
        "        # write the forward pass here. Combine knn with the forward pass of EdgeConv2d\n",
        "        idx = knn(x, self.k).to(DEVICE)\n",
        "        x = EdgeConv2d.forward(self, x, idx)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi1kie3r8kKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.randn(8, 3, 100, 1)\n",
        "print(x.shape)\n",
        "out = DynEdgeConv2d(3, 64)(x)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3X4dwlt8kKX",
        "colab_type": "text"
      },
      "source": [
        "## 3.4 Simple version of DGCNN (10')\n",
        "\n",
        "Instead of reimplementing DGCNN, lets simply replace the MLP layers in the backbone of PointNet and see its performance. \n",
        "To make work easier, let us also remove the annoying T-Net. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iomvlfT8kKX",
        "colab_type": "text"
      },
      "source": [
        "### TASK3.4: Write the SimpleGCNN class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ-f0q9h8kKY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SimpleDGCNN(nn.Module):\n",
        "    def __init__(self, num_classes=40):\n",
        "        super(SimpleDGCNN, self).__init__()\n",
        "\n",
        "        # Look at PointNet backbone.\n",
        "        # There are conv1d layer: 3 --> 64 --> 128 -->1024.\n",
        "        # Then MLP classifier. \n",
        "        \n",
        "        # Here we keep the classifier part the same. But change the backbone into dynamic EdgeConv. \n",
        "        # k=9, use relu and bachnormalization. Other parameters keep the default. \n",
        "        self.convs = Seq(\n",
        "            DynEdgeConv2d(3, 64),\n",
        "            DynEdgeConv2d(64, 128),\n",
        "            DynEdgeConv2d(128, 1024)\n",
        "        )\n",
        "\n",
        "        self.classifier = Seq(\n",
        "            Conv1dLayer([1024, 512]),\n",
        "            MLP([512, 256], dropout=0.5),\n",
        "            Conv1dLayer([256, num_classes], norm=False, act=None)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # x should be [B, C, N, 1]\n",
        "        if len(x.shape)<4:\n",
        "            x = x.unsqueeze(-1)\n",
        "        \n",
        "        # dynamic edgeConvolution layers\n",
        "        x = self.convs(x)\n",
        "        # max pooling layer \n",
        "        x = torch.max(x, dim=2, keepdim=True)[0]\n",
        "        x = x.view(x.shape[0],x.shape[1],-1)\n",
        "        global_feature = x.view(-1, 1024)\n",
        "\n",
        "        out = self.classifier(x)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3CIhgMs8kKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## random generate data and test this network\n",
        "x = torch.randn(8, 3, 100, 1).to(DEVICE)\n",
        "net = SimpleDGCNN().to(DEVICE)\n",
        "out = net(x)\n",
        "print(out.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8sX6wzA8kKb",
        "colab_type": "text"
      },
      "source": [
        "## 3.5 Train SimpleDGCNN on ModelNet40 (5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24JhJs8_8kKc",
        "colab_type": "text"
      },
      "source": [
        "### Modify the train_step and test function in PartNet. (5')\n",
        "You do not have to change too much, just make some necessary small changes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH06SHWX8kKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(model, train_loader, optimizer, criterion, train_losses):\n",
        "    # todo:\n",
        "    model.train()\n",
        "\n",
        "    train_pred = []\n",
        "    train_true = []\n",
        "    for i, (data, label) in enumerate(train_loader):\n",
        "        if i%100 == 0: print('train_step ', i)\n",
        "        # todo: data preprocess (to GPU, and permute)\n",
        "        data, label = data.to(DEVICE), label.to(DEVICE)\n",
        "\n",
        "        # TASK 2.4 todo: optimizer zero grad, forward pass, criterion\n",
        "        # optimizer zero grad\n",
        "            # TASK 2.4 todo: \n",
        "        optimizer.zero_grad()\n",
        "            \n",
        "        # forward pass\n",
        "            # TASK 2.4 todo:\n",
        "        logits = model(data.transpose(1,2))\n",
        "        # criterion\n",
        "            # TASK 2.4 todo: \n",
        "        loss = criterion(logits, label)\n",
        "        \n",
        "        # backward part and optimize\n",
        "        # TASK 2.4 todo:\n",
        "        loss.backward() ##\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.update(loss.item())\n",
        "\n",
        "        preds = logits.max(dim=1)[1]\n",
        "        train_true.append(label.cpu().numpy())\n",
        "        train_pred.append(preds.detach().cpu().numpy())\n",
        "\n",
        "    train_true = np.concatenate(train_true)\n",
        "    train_pred = np.concatenate(train_pred)\n",
        "    overall_acc = metrics.accuracy_score(train_true, train_pred)\n",
        "    class_avg_acc = metrics.balanced_accuracy_score(train_true, train_pred)\n",
        "    \n",
        "    print('\\rTrain Iter: [{:03d}/{:03d}] Loss: {:.4f} OA:{:.4f} AvgAcc:{:.4f}'.format(i+1, len(train_loader), loss.item(), overall_acc, class_avg_acc, end='', flush=True))\n",
        "    return overall_acc, class_avg_acc, train_losses\n",
        "\n",
        "\n",
        "def test(model, test_loader, criterion, test_losses):\n",
        "    # todo:\n",
        "    model.eval()\n",
        "    test_true = []\n",
        "    test_pred = []\n",
        "    with torch.no_grad():\n",
        "      for i, (data, label) in enumerate(test_loader):\n",
        "        if i%100 == 0: print('test ', i)\n",
        "        data, label = data.to(DEVICE), label.to(DEVICE)\n",
        "        # test forward and loss\n",
        "        # TASK 2.4 todo: \n",
        "        logits = model(data.transpose(1,2))\n",
        "        loss = criterion(logits, label)  \n",
        "\n",
        "        pred = logits.max(dim=1)[1]\n",
        "        test_true.append(label.cpu().numpy())\n",
        "        test_pred.append(pred.detach().cpu().numpy())\n",
        "\n",
        "        test_losses.update(loss.item())\n",
        "\n",
        "      test_true = np.concatenate(test_true)\n",
        "      test_pred = np.concatenate(test_pred)\n",
        "      overall_acc = metrics.accuracy_score(test_true, test_pred)\n",
        "      class_avg_acc = metrics.balanced_accuracy_score(test_true, test_pred)\n",
        "\n",
        "      print('\\rTest Iter: [{:03d}/{:03d}] Loss: {:.4f} OA:{:.4f} AvgAcc:{:.4f}'.format(i+1, len(train_loader), loss.item(), overall_acc, class_avg_acc, end='', flush=True))\n",
        "    return overall_acc, class_avg_acc, test_losses\n",
        "\n",
        "def train_cls(train_loader, test_loader, network, optimizer, scheduler, criterion, epochs):\n",
        "    reg = OrthoLoss()\n",
        "    train_losses, test_losses = AverageMeter(), AverageMeter()\n",
        "    best_test_overall_acc = 0. \n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch:[{:02d}/{:02d}]'.format(epoch+1, epochs))\n",
        "        train_overall_acc, train_class_avg_acc, train_losses = train_step(network, train_loader, optimizer, criterion, train_losses)\n",
        "        test_overall_acc, test_class_avg_acc, test_losses = test(network, test_loader, criterion, test_losses)\n",
        "        \n",
        "        if test_overall_acc > best_test_overall_acc:\n",
        "            best_test_overall_acc = test_overall_acc\n",
        "            class_avg_acc_when_best = test_class_avg_acc\n",
        "            print(\"Got a new best model on Test with Overall ACC {:.4f}. \"\n",
        "                         \"Its avg acc is {:.4f}\".format(best_test_overall_acc, class_avg_acc_when_best))\n",
        "            save_ckpt(network, optimizer, scheduler, 'PointNet', 'best')\n",
        "            \n",
        "        scheduler.step()\n",
        "        print('Average Train Loss: {:.4f}; Train Overall Acc: {:.4f}; Test Overall ACC: {:.4f}; Best Test Overall Acc {:.4f}'.format(train_losses.avg, train_overall_acc, test_overall_acc, best_test_overall_acc))\n",
        "        \n",
        "        print(\"------------------------------------------------------------\\n\")\n",
        "    print('Finish Training PointNet. The best Test overall acc {:.4f}'.format(best_test_overall_acc))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbzMo9w_8kKd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "epochs = 100\n",
        "batch_size=32\n",
        "test_batch_size = 50\n",
        "lr = 0.001 \n",
        "\n",
        "network = SimpleDGCNN(40).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(network.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, eta_min=lr)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#######3\n",
        "train_loader = DataLoader(ModelNet40(partition='train', num_points=1024),\n",
        "                          num_workers=4, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(ModelNet40(partition='test', num_points=1024),\n",
        "                         num_workers=4, batch_size=test_batch_size, shuffle=True, drop_last=False)\n",
        "\n",
        "# start training\n",
        "# this may take 8 hours on Titan 1080Ti\n",
        "train_cls(train_loader, test_loader, network, optimizer, scheduler, criterion, epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-V0KnTHR8kKi",
        "colab_type": "text"
      },
      "source": [
        "## TASK 3.6 Fill in your best overall accuracy on testing dataset here. (should be higher than 90.0%)  (5')"
      ]
    }
  ]
}